{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBK Demo, 07/2019\n",
    "\n",
    "## Step 0 - System and Connection Check\n",
    "- Start with gpstate. Use jupyter, dbeaver or pgadmin for queries.\n",
    "- Check *gp_autostats_mode* is set to **NONE**. This will avoid analyze time in loading and is required for one of the steps when running explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "connection_string = os.getenv('GPDBCONN')\n",
    "\n",
    "cs = re.match('^postgresql:\\/\\/(\\S+):(\\S+)@(\\S+):(\\S+)\\/(\\S+)$', connection_string)\n",
    "\n",
    "db_usr      = cs.group(1)\n",
    "db_pwd      = cs.group(2)\n",
    "db_host_ip   = cs.group(3)\n",
    "db_host_port = cs.group(4)\n",
    "db_host_db   = cs.group(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Connected: gpadmin@gpadmin'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext sql\n",
    "%sql $connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://gpadmin:***@10.0.2.15:5432/gpadmin\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>gp_autostats_mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ON_NO_STATS</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'ON_NO_STATS',)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SHOW gp_autostats_mode;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://gpadmin:***@10.0.2.15:5432/gpadmin\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SET gp_autostats_mode = 'NONE';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://gpadmin:***@10.0.2.15:5432/gpadmin\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>version</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>PostgreSQL 8.3.23 (Greenplum Database 5.21.0 build commit:27db6bab4c909daa8d6699d94cabc48f87b07fab) on x86_64-pc-linux-gnu, compiled by GCC gcc (GCC) 6.2.0, 64-bit compiled on Jul 12 2019 23:39:01</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'PostgreSQL 8.3.23 (Greenplum Database 5.21.0 build commit:27db6bab4c909daa8d6699d94cabc48f87b07fab) on x86_64-pc-linux-gnu, compiled by GCC gcc (GCC) 6.2.0, 64-bit compiled on Jul 12 2019 23:39:01',)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT version();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. The Amazon Customer Reviews Dataset\n",
    "\n",
    "Over 130+ million customer reviews are available to researchers as part of this release. The data is available in TSV files in the amazon-reviews-pds S3 bucket in AWS US East Region. Each line in the data files corresponds to an individual review (tab delimited, with no quote and escape characters). Samples of the data are available in English and French; more details on the information in each column can be found [here](https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt).\n",
    "\n",
    "If you use the AWS Command Line Interface, you can list data in the bucket with the `ls` command: \n",
    "\n",
    "```aws s3 ls s3://amazon-reviews-pds/tsv/```\n",
    "\n",
    "To download data using the AWS Command Line Interface, you can use the `cp` command. For instance, the following command will copy the file named `amazon_reviews_us_Camera_v1_00.tsv.gz` to your local directory:\n",
    "\n",
    "```aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz```\n",
    "\n",
    "For our demo, we choose to download three files under the `/home/gpadmin/data/` folder, using the `aws s3 cp <S3 File> <Local File>` command described above:\n",
    "- [`s3://amazon-reviews-pds/tsv/amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz`](s3://amazon-reviews-pds/tsv/amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz) (~185MB)\n",
    "- [`s3://amazon-reviews-pds/tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz`](s3://amazon-reviews-pds/tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz) (~22MB)\n",
    "- [`s3://amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz`](s3://amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz) (~489MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create Database Table to hold the Dataset\n",
    "\n",
    "### Create the Schema (optional) and the Database Table to hold the dataset, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP SCHEMA IF EXISTS demo CASCADE;\r\n",
      "\r\n",
      "CREATE SCHEMA demo;\r\n",
      "\r\n",
      "DROP TABLE IF EXISTS demo.amzn_reviews;\r\n",
      "\r\n",
      "\r\n",
      "CREATE TABLE demo.amzn_reviews(\r\n",
      "  marketplace TEXT, \r\n",
      "  customer_id TEXT, \r\n",
      "  review_id TEXT, \r\n",
      "  product_id TEXT, \r\n",
      "  product_parent TEXT, \r\n",
      "  product_title TEXT, \r\n",
      "  product_category TEXT, \r\n",
      "  star_rating TEXT, \r\n",
      "  helpful_votes TEXT, \r\n",
      "  total_votes TEXT, \r\n",
      "  vine TEXT, \r\n",
      "  verified_purchase TEXT, \r\n",
      "  review_headline TEXT, \r\n",
      "  review_body TEXT, \r\n",
      "  review_date TEXT)\r\n",
      "DISTRIBUTED BY (review_id);\r\n"
     ]
    }
   ],
   "source": [
    "!cat gp-demo/script/2-1-create-db-schema-table.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://gpadmin:***@10.0.2.15:5432/gpadmin\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = !cat gp-demo/script/2-1-create-db-schema-table.sql\n",
    "\n",
    "%sql {''.join(query)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM demo.amzn_reviews;\r\n"
     ]
    }
   ],
   "source": [
    "!cat gp-demo/script/2-2-count-table.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://gpadmin:***@10.0.2.15:5432/gpadmin\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0L,)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = !cat gp-demo/script/2-2-count-table.sql\n",
    "%sql {''.join(query)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Load dataset into the database using `gpload`.\n",
    "\n",
    "**gpload** is a data loading utility that acts as an interface to the Greenplum Database external table parallel loading feature. Using a load specification defined in a YAML formatted control file, gpload executes a load by invoking the Greenplum Database parallel file server (*gpfdist*), creating an external table definition based on the source data defined, and executing an INSERT, UPDATE or MERGE operation to load the source data into the target table in the database. \n",
    "\n",
    "You can declare more than one file as input/source as long as the data is of the same format in all files specified. Additionally, if the files are compressed using gzip or bzip2 (have a .gz or .bz2 file extension), the files will be uncompressed automatically (provided that `gunzip` or `bunzip2` is in your path). You can also declare options such as the schema of the source data files, perform basic transformations,  define custom delimiter and/or escape character(s), and many more. For the full list of available options, check the GPLoad Utility Reference available on [Pivotal Greenplum Database Documentation](https://gpdb.docs.pivotal.io/latest) (*Pivotal Greenplum Documentation* > *Utility Guide* > *Management Utility Reference* > *gpload*).\n",
    "\n",
    "The operation, including any SQL commands specified in the SQL collection of the YAML control file, are performed as a single transaction to prevent inconsistent data when performing multiple, simultaneous load operations on a target table.\n",
    "\n",
    "For our demo, we the **gpload_amzn_reviews.yaml** file, as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION: 1.0.0.1\r\n",
      "GPLOAD:\r\n",
      "   INPUT:\r\n",
      "    - SOURCE:\r\n",
      "         FILE:\r\n",
      "           - /home/gpadmin/data/amzn_reviews*.tsv.gz\r\n",
      "    - FORMAT: text\r\n",
      "    - HEADER: true\r\n",
      "    - LOG_ERRORS: true\r\n",
      "    - MAX_LINE_LENGTH: 1000000\r\n",
      "    - ERROR_LIMIT: 50000\r\n",
      "   OUTPUT:\r\n",
      "    - TABLE: demo.amzn_reviews\r\n",
      "    - MODE: insert\r\n",
      "   PRELOAD:\r\n",
      "    - TRUNCATE: true\r\n",
      "    - REUSE_TABLES: true\r\n"
     ]
    }
   ],
   "source": [
    "!cat gp-demo/script/3-1-gpload-amzn-reviews.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-1-gpload-amzn-reviews.yaml                  100%  353   446.0KB/s   00:00    \n",
      "2019-07-26 14:52:03|INFO|gpload session started 2019-07-26 14:52:03\n",
      "2019-07-26 14:52:03|INFO|no host supplied, defaulting to localhost\n",
      "2019-07-26 14:52:03|INFO|started gpfdist -p 8000 -P 9000 -f \"/home/gpadmin/data/amzn_reviews*.tsv.gz\" -t 30 -m 1000000\n",
      "2019-07-26 14:52:03|INFO|did not find an external table to reuse. creating ext_gpload_reusable_ee043088_afb4_11e9_8538_080027acd876\n",
      "2019-07-26 14:52:49|WARN|134 bad rows\n",
      "2019-07-26 14:52:49|WARN|Please use following query to access the detailed error\n",
      "2019-07-26 14:52:49|WARN|select * from gp_read_error_log('ext_gpload_reusable_ee043088_afb4_11e9_8538_080027acd876') where cmdtime > to_timestamp('1564152723.37')\n",
      "2019-07-26 14:52:49|INFO|running time: 45.85 seconds\n",
      "2019-07-26 14:52:49|INFO|rows Inserted          = 3453164\n",
      "2019-07-26 14:52:49|INFO|rows Updated           = 0\n",
      "2019-07-26 14:52:49|INFO|data formatting errors = 134\n",
      "2019-07-26 14:52:49|INFO|gpload succeeded with warnings\n"
     ]
    }
   ],
   "source": [
    "!scp gp-demo/script/3-1-gpload-amzn-reviews.yaml $db_usr@$db_host_ip:gpload_amzn_reviews.yaml\n",
    "!ssh $db_usr@$db_host_ip 'gpload -d gpadmin -f /home/gpadmin/gpload_amzn_reviews.yaml 2>&1 \\\n",
    "    | tee /home/gpadmin/gpload_amzn_reviews.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check `gpload` execution\n",
    "\n",
    "Check `gpload` execution output (shown above and also available on `/home/gpadmin/script/gpload_amzn_reviews.log`), confirm successful loading of the data and/or identify any message which require ones attention and/or actions:\n",
    "\n",
    "### 1. Check the data has been properly loaded, by confirming row count shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql SELECT COUNT(*) \n",
    "FROM demo.amzn_reviews;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check data formatting errors and row counts, if identified by the `gpload` execution log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) \\\n",
    "    FROM gp_read_error_log('ext_gpload_reusable_3168f2da_aee0_11e9_a57d_080027acd876') \\\n",
    "    WHERE cmdtime > to_timestamp('1564061353.64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * \\\n",
    "    FROM gp_read_error_log('ext_gpload_reusable_3168f2da_aee0_11e9_a57d_080027acd876') \\\n",
    "    WHERE cmdtime > to_timestamp('1564061353.64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Familiarize yourself with the newly loaded data table\n",
    "\n",
    "### 1. DESCRIBE *demo.amzn_reviews* table using psql utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "psql_cmd = !psql -H -h $host_ip -U $usr -c '\\d demo.amzn_reviews'\n",
    "\n",
    "display_html(''.join(psql_cmd), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DESCRIBE *demo.amzn_reviews* table using *information_schema* database catalog table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM information_schema.COLUMNS\n",
    "WHERE TABLE_NAME = 'amzn_reviews';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve a sample of the demo.amzn_reviews table data (10 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM demo.amzn_reviews LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show *demo.amzn_reviews* table data distribution across segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT gp_segment_id, count(*) FROM demo.amzn_reviews GROUP BY 1 ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Partitioning\n",
    "\n",
    "### 1. Create a new copy of the original table, define a *PARTITION* pattern (by month) and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "CREATE TABLE demo.amzn_reviews_v2(\n",
    "  marketplace TEXT, \n",
    "  customer_id BIGINT, \n",
    "  review_id TEXT, \n",
    "  product_id TEXT, \n",
    "  product_parent BIGINT, \n",
    "  product_title TEXT, \n",
    "  product_category TEXT, \n",
    "  star_rating INTEGER, \n",
    "  helpful_votes INTEGER, \n",
    "  total_votes INTEGER, \n",
    "  vine TEXT, \n",
    "  verified_purchase TEXT, \n",
    "  review_headline TEXT, \n",
    "  review_body TEXT, \n",
    "  review_date DATE)\n",
    "DISTRIBUTED BY (review_id)\n",
    "PARTITION BY RANGE(review_date) \n",
    "(\n",
    "    START ('1998-07-01'::date) END ('2015-09-01'::date)\n",
    "    EVERY ('1 month'::interval)\n",
    ");\n",
    "\n",
    "INSERT INTO demo.amzn_reviews_v2\n",
    "SELECT * FROM demo.amzn_reviews;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show row count per partition for the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT tableoid::regclass, count(*) FROM demo.amzn_reviews_v2 GROUP BY 1 ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Demonstrate *Partition Elimination* functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql -d gpadmin -U gpadmin -h 10.0.2.15 -f './scripts/explain_example_1_1.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql_out = !psql -H -d gpadmin -U gpadmin -h 10.0.2.15 -f './scripts/example_1_2.sql'\n",
    "\n",
    "display_html(''.join(psql_out), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXPLAIN\n",
    "SELECT COUNT(*)\n",
    "    , date_part('year', review_date::DATE) AS YEAR_NUM\n",
    "    , date_part('month', review_date::DATE) AS MONTH_NUM\n",
    "FROM demo.amzn_reviews_v2\n",
    "GROUP BY 2, 3\n",
    "ORDER BY 2, 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the three tables:\n",
    "- Load heap table with gpload (gpload_h.yaml):\n",
    "\n",
    "```yaml\n",
    "VERSION: 1.0.0.1\n",
    "GPLOAD:\n",
    "   INPUT:\n",
    "    - SOURCE:\n",
    "         FILE:\n",
    "           - /home/gpadmin/data/crimes_all.txt\n",
    "    - FORMAT: text\n",
    "    - DELIMITER: '|'\n",
    "    - LOG_ERRORS: true\n",
    "    - ERROR_LIMIT: 50000\n",
    "   OUTPUT:\n",
    "    - TABLE: demo.fact_crimes_heap\n",
    "    - MODE: insert\n",
    "   PRELOAD:\n",
    "    - TRUNCATE: true\n",
    "    - REUSE_TABLES: true\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS demo.fact_crimes_heap;\n",
    "\n",
    "CREATE TABLE demo.fact_crimes_heap\n",
    "(\n",
    "  id INT\n",
    "  , case_number VARCHAR (20)\n",
    "  , crime_date TIMESTAMP\n",
    "  , block VARCHAR(50)\n",
    "  , IUCR VARCHAR(10)\n",
    "  , primary_type VARCHAR(50)\n",
    "  , description VARCHAR(75)\n",
    "  , location_desc VARCHAR (75)\n",
    "  , arrest VARCHAR(5)\n",
    "  , domestic VARCHAR(5)\n",
    "  , beat VARCHAR(7)\n",
    "  , district VARCHAR(7)\n",
    "  , ward SMALLINT\n",
    "  , community_area VARCHAR(10)\n",
    "  , fbi_code VARCHAR(5)\n",
    "  , x_coord FLOAT\n",
    "  , y_coord FLOAT\n",
    "  , crime_year SMALLINT\n",
    "  , record_update_date TIMESTAMP\n",
    "  , latitude FLOAT\n",
    "  , longitude FLOAT\n",
    "  , location VARCHAR (60),\n",
    "  historical int null,\n",
    "  zipcode int null,\n",
    "  community int null, \n",
    "  census int null,\n",
    "  wards int null,\n",
    "  boundaries int null, \n",
    "  policedistrict int null, \n",
    "  policebeats int null\t)\n",
    "distributed by (id);\n",
    "\n",
    "DROP TABLE IF EXISTS demo.fact_crimes_row_comp;\n",
    "\n",
    "CREATE TABLE demo.fact_crimes_row_comp\n",
    "(\n",
    "  id INT\n",
    "  , case_number VARCHAR (20)\n",
    "  , crime_date TIMESTAMP\n",
    "  , block VARCHAR(50)\n",
    "  , IUCR VARCHAR(10)\n",
    "  , primary_type VARCHAR(50)\n",
    "  , description VARCHAR(75)\n",
    "  , location_desc VARCHAR (75)\n",
    "  , arrest VARCHAR(5)\n",
    "  , domestic VARCHAR(5)\n",
    "  , beat VARCHAR(7)\n",
    "  , district VARCHAR(7)\n",
    "  , ward SMALLINT\n",
    "  , community_area VARCHAR(10)\n",
    "  , fbi_code VARCHAR(5)\n",
    "  , x_coord FLOAT\n",
    "  , y_coord FLOAT\n",
    "  , crime_year SMALLINT\n",
    "  , record_update_date TIMESTAMP\n",
    "  , latitude FLOAT\n",
    "  , longitude FLOAT\n",
    "  , location VARCHAR (60),\n",
    "  historical int null,\n",
    "  zipcode int null,\n",
    "  community int null, \n",
    "  census int null,\n",
    "  wards int null,\n",
    "  boundaries int null, \n",
    "  policedistrict int null, \n",
    "  policebeats int null\t)\n",
    "WITH (appendonly=true, orientation=row, compresstype=zlib, compresslevel=3)\n",
    "distributed by (id);\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS demo.fact_crimes_col_comp;\n",
    "\n",
    "CREATE TABLE demo.fact_crimes_col_comp\n",
    "(\n",
    "  id INT\n",
    "  , case_number VARCHAR (20)\n",
    "  , crime_date TIMESTAMP\n",
    "  , block VARCHAR(50)\n",
    "  , IUCR VARCHAR(10)\n",
    "  , primary_type VARCHAR(50)\n",
    "  , description VARCHAR(75)\n",
    "  , location_desc VARCHAR (75)\n",
    "  , arrest VARCHAR(5)\n",
    "  , domestic VARCHAR(5)\n",
    "  , beat VARCHAR(7)\n",
    "  , district VARCHAR(7)\n",
    "  , ward SMALLINT\n",
    "  , community_area VARCHAR(10)\n",
    "  , fbi_code VARCHAR(5)\n",
    "  , x_coord FLOAT\n",
    "  , y_coord FLOAT\n",
    "  , crime_year SMALLINT\n",
    "  , record_update_date TIMESTAMP\n",
    "  , latitude FLOAT\n",
    "  , longitude FLOAT\n",
    "  , location VARCHAR (60),\n",
    "  historical int null,\n",
    "  zipcode int null,\n",
    "  community int null, \n",
    "  census int null,\n",
    "  wards int null,\n",
    "  boundaries int null, \n",
    "  policedistrict int null, \n",
    "  policebeats int null\t)\n",
    "WITH (appendonly=true, orientation=column, compresstype=zlib, compresslevel=3)\n",
    "distributed by (id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'gpload -d gpadmin -f /home/gpadmin/gpload_h.yaml > /home/gpadmin/gpload_h.log 2>&1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Heap table loaded data from the same source file in <33 seconds (heap vs compressed table loading has different performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load **demo.fact_row_comp** table with data from the **heap** table above, and check timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DELETE FROM demo.fact_crimes_row_comp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`INSERT INTO demo.fact_crimes_row_comp SELECT * FROM demo.fact_crimes;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'psql postgresql://gpadmin:z3huyg3gyfll2@13.64.71.99:5432/gpadmin -f insert_into_row_comp.sql '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load **demo.fact_col_comp** table with data from the **heap** table above, and check timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DELETE FROM demo.fact_crimes_col_comp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`INSERT INTO demo.fact_crimes_col_comp SELECT * FROM demo.fact_crimes;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'psql postgresql://gpadmin:z3huyg3gyfll2@13.64.71.99:5432/gpadmin -f insert_into_col_comp.sql '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the size of each of the three tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT pg_size_pretty(pg_relation_size('demo.fact_crimes_heap'))::TEXT, 'demo.fact_crimes_heap' AS TABLENAME\n",
    "UNION\n",
    "SELECT pg_size_pretty(pg_relation_size('demo.fact_crimes_row_comp'))::TEXT AS TABLESIZE, 'demo.fact_crimes_row_comp' AS TABLENAME\n",
    "UNION ALL\n",
    "SELECT pg_size_pretty(pg_relation_size('demo.fact_crimes_col_comp')) AS TABLESIZE, 'demo.fact_crimes_col_comp' AS TABLENAME;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** \n",
    "- Heap table has no compression. It is best for staging tables or when frequent updates/ deletes are needed.\n",
    "- Row oriented has the best compression. It is best for frequent inserts and `SELECT`'s on all/ most of the columns.\n",
    "- Column oriented also has better compression than the heap table but not from the row-oriented table. It is best for static partitions/ tables and `SELECT`'s on fewer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. EXPLAIN plans, & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXPLAIN SELECT location_desc\n",
    "\t, count(case_number)\n",
    "FROM\n",
    "\tdemo.fact_crimes\n",
    "WHERE\n",
    "\tcrime_date >= '2014-01-01'\n",
    "\tAND crime_date <= '2014-12-31'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'psql postgresql://gpadmin:z3huyg3gyfll2@13.64.71.99:5432/gpadmin -f explain_select.sql'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- Copy `EXPLAIN` plan created above and paste it in : http://planchecker.cfapps.io/\n",
    "- Planchecker app will provide recommendation(s) about collecting statistics. Highlight this as a recommendation that database provides for optimizations.\n",
    "- Use the `ANALYZE` utility to collect statistics for optimizer, missing or stale statistics; all the above can generate bad plans.\n",
    "- Use the `ANALYZEDB` utility and scheduled it to run frequently i.e. everyday, to collect statistics on changed tables/ partitions only since last run. \n",
    "- The same utility can also be easily stopped and resumed. \n",
    "- There is no need for DBA to explicitly look for different stats collection policies for different types of tables/ partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'psql postgresql://gpadmin:z3huyg3gyfll2@13.64.71.99:5432/gpadmin -c \"analyze demo.fact_crimes\"'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -i /root/gpdb-gcp.key gpadmin@13.64.71.99 'psql postgresql://gpadmin:z3huyg3gyfll2@13.64.71.99:5432/gpadmin -f explain_select.sql'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
